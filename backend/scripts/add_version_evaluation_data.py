#!/usr/bin/env python3
"""
ê°™ì€ ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ ë°ì´í„° ì¶”ê°€

í”„ë¡œë•ì…˜ ì§€ì • í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•œ ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ë³„ë¡œ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
import os
from datetime import datetime, timezone

# ë°±ì—”ë“œ í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database import database
from sqlalchemy import text


async def add_version_evaluation_data():
    """ê°™ì€ ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ ì¶”ê°€"""
    print("ğŸš€ ë…¸ë“œë³„ ë²„ì „ í‰ê°€ ê²°ê³¼ ë°ì´í„° ì¶”ê°€ ì‹œì‘")
    
    try:
        await database.connect()
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # í˜„ì¬ ì‹œê°„
        now = datetime.now(timezone.utc).isoformat()
        
        # ê²€ìƒ‰ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ ë°ì´í„°
        search_node_evaluations = [
            # ê²€ìƒ‰ë…¸ë“œ ë²„ì „ë³„ accuracy ë©”íŠ¸ë¦­
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (1, 1, 'accuracy', 0.85, '{now}');",  # ê²€ìƒ‰ë…¸ë“œ v1
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (3, 1, 'accuracy', 0.92, '{now}');",  # ê²€ìƒ‰ë…¸ë“œ v2 (í”„ë¡œë•ì…˜)
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (12, 1, 'accuracy', 0.88, '{now}');", # ê²€ìƒ‰ë…¸ë“œ v3
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (13, 1, 'accuracy', 0.95, '{now}');", # ê²€ìƒ‰ë…¸ë“œ v4
            
            # ê²€ìƒ‰ë…¸ë“œ ë²„ì „ë³„ response_time ë©”íŠ¸ë¦­
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (1, 1, 'response_time', 0.75, '{now}');",  # ê²€ìƒ‰ë…¸ë“œ v1
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (3, 1, 'response_time', 0.82, '{now}');",  # ê²€ìƒ‰ë…¸ë“œ v2
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (12, 1, 'response_time', 0.89, '{now}');", # ê²€ìƒ‰ë…¸ë“œ v3
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (13, 1, 'response_time', 0.91, '{now}');", # ê²€ìƒ‰ë…¸ë“œ v4
        ]
        
        # ìš”ì•½ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ ë°ì´í„° 
        summary_node_evaluations = [
            # ìš”ì•½ë…¸ë“œ ë²„ì „ë³„ completeness ë©”íŠ¸ë¦­
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (2, 1, 'completeness', 0.78, '{now}');",  # ìš”ì•½ë…¸ë“œ v1
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (7, 1, 'completeness', 0.84, '{now}');",  # ìš”ì•½ë…¸ë“œ v2
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (14, 1, 'completeness', 0.87, '{now}');", # ìš”ì•½ë…¸ë“œ v3
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (16, 1, 'completeness', 0.93, '{now}');", # ìš”ì•½ë…¸ë“œ v5 (í”„ë¡œë•ì…˜)
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (17, 1, 'completeness', 0.89, '{now}');", # ìš”ì•½ë…¸ë“œ v6
            f"INSERT INTO evaluation_results (prompt_id, dataset_id, metric_name, score, created_at) VALUES (20, 1, 'completeness', 0.91, '{now}');", # ìš”ì•½ë…¸ë“œ v7
        ]
        
        all_evaluations = search_node_evaluations + summary_node_evaluations
        
        print(f"ğŸ“ˆ {len(all_evaluations)}ê°œì˜ í‰ê°€ ê²°ê³¼ ë°ì´í„° ì¶”ê°€ ì¤‘...")
        
        added_count = 0
        for i, sql in enumerate(all_evaluations, 1):
            try:
                await database.execute(sql)
                # ê°„ëµí•˜ê²Œ í‘œì‹œ
                if "ê²€ìƒ‰ë…¸ë“œ" in sql or i <= 8:
                    node_type = "ê²€ìƒ‰ë…¸ë“œ" if i <= 8 else "ìš”ì•½ë…¸ë“œ"
                    version = ((i-1) % 4) + 1 if i <= 8 else [1,2,3,5,6,7][(i-9) % 6]
                    metric = "accuracy/response_time" if i <= 8 else "completeness"
                    print(f"âœ… {node_type} v{version} ({metric}) ì¶”ê°€ ì„±ê³µ")
                added_count += 1
            except Exception as e:
                print(f"âŒ ë°ì´í„° {i} ì¶”ê°€ ì‹¤íŒ¨: {e}")
        
        print(f"\nğŸ‰ ì´ {added_count}ê°œì˜ í‰ê°€ ê²°ê³¼ ë°ì´í„°ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ì¶”ê°€ëœ ë°ì´í„° ê²€ì¦ - ê²€ìƒ‰ë…¸ë“œ accuracy ê¸°ì¤€
        print(f"\nğŸ” ê²€ìƒ‰ë…¸ë“œ accuracy ë©”íŠ¸ë¦­ ê²°ê³¼ í™•ì¸:")
        verify_sql = """
            SELECT 
                er.id, er.score, p.node_name, p.version, p.production,
                d.name as dataset_name, er.metric_name
            FROM evaluation_results er
            JOIN prompts p ON er.prompt_id = p.id
            JOIN datasets d ON er.dataset_id = d.id
            WHERE p.node_name = 'ê²€ìƒ‰ë…¸ë“œ' AND er.metric_name = 'accuracy'
            ORDER BY p.version
        """
        
        results = await database.fetch_all(text(verify_sql))
        
        print("ğŸ“Š ê²€ìƒ‰ë…¸ë“œ ë²„ì „ë³„ accuracy ì ìˆ˜:")
        for result in results:
            production_mark = " ğŸ”¥(í”„ë¡œë•ì…˜)" if result['production'] else ""
            print(f"   ğŸ“ˆ ë²„ì „ {result['version']}: ì ìˆ˜ {result['score']}{production_mark}")
        
        # ìš”ì•½ë…¸ë“œ completeness ê²°ê³¼ë„ í™•ì¸
        print(f"\nğŸ” ìš”ì•½ë…¸ë“œ completeness ë©”íŠ¸ë¦­ ê²°ê³¼ í™•ì¸:")
        verify_sql2 = """
            SELECT 
                er.id, er.score, p.node_name, p.version, p.production,
                d.name as dataset_name, er.metric_name
            FROM evaluation_results er
            JOIN prompts p ON er.prompt_id = p.id
            JOIN datasets d ON er.dataset_id = d.id
            WHERE p.node_name = 'ìš”ì•½ë…¸ë“œ' AND er.metric_name = 'completeness'
            ORDER BY p.version
        """
        
        results2 = await database.fetch_all(text(verify_sql2))
        
        print("ğŸ“Š ìš”ì•½ë…¸ë“œ ë²„ì „ë³„ completeness ì ìˆ˜:")
        for result in results2:
            production_mark = " ğŸ”¥(í”„ë¡œë•ì…˜)" if result['production'] else ""
            print(f"   ğŸ“ˆ ë²„ì „ {result['version']}: ì ìˆ˜ {result['score']}{production_mark}")
        
        print(f"\nâœ… ì™„ë£Œ! ì´ì œ UIì—ì„œ ê°™ì€ ë…¸ë“œì˜ ì—¬ëŸ¬ ë²„ì „ ì¤‘ í”„ë¡œë•ì…˜ì„ ì„ íƒí•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("ğŸ¯ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:")
        print("   1. ê²€ìƒ‰ë…¸ë“œ - accuracy ë©”íŠ¸ë¦­ìœ¼ë¡œ v1~v4 ì¤‘ í”„ë¡œë•ì…˜ ë³€ê²½")
        print("   2. ìš”ì•½ë…¸ë“œ - completeness ë©”íŠ¸ë¦­ìœ¼ë¡œ v1~v7 ì¤‘ í”„ë¡œë•ì…˜ ë³€ê²½") 
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    finally:
        await database.disconnect()
        print("ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")


if __name__ == "__main__":
    asyncio.run(add_version_evaluation_data())